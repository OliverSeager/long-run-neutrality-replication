{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dcdb407",
   "metadata": {},
   "source": [
    "## Calculating Distance to Default\n",
    "\n",
    "**Oliver Seager <br>\n",
    "o.j.seager@lse.ac.uk <br>\n",
    "Python 3.9.7**\n",
    "\n",
    "**Created:** 03/12/2021 <br>\n",
    "**Last Modified:** 08/04/2021\n",
    "\n",
    "We use the Black-Scholes-Merton model (Merton, 1974) to infer distance to default using a methodology from Vassalou and Xing (2004), Bohn and Crosbie (2003), and Bharath and Shumway (2008). \n",
    "\n",
    "With equity $E$, debt $D$, risk-free interest rate $r$ and time horizon $T$ observable, we use an iterative procedure to back out value $V$ and daily volatility $\\sigma_V$ from the below relation of equity and debt to value...\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta_1 &:= \\frac{\\log\\left(\\frac{V}{D}\\right) + \\left(r + \\frac{1}{2}\\sigma_V^2 \\right)T}{\\sigma_V \\sqrt{T}}, \\\\\n",
    "~\\\\\n",
    "\\delta_2 &:= \\frac{\\log\\left(\\frac{V}{D}\\right) + \\left(r - \\frac{1}{2}\\sigma_V^2 \\right)T}{\\sigma_V \\sqrt{T}}, \\\\\n",
    "~\\\\\n",
    "E &= V\\Phi(\\delta_1) - e^{-r}D\\Phi(\\delta_2).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "...where $\\Phi$ gives the cumulative distribution function of the standard normal distribution.\n",
    "\n",
    "We take $T$ to be 253 - roughly the number of trading days each year in the NYSE...\n",
    "\n",
    "$$\n",
    "T = 253.\n",
    "$$\n",
    "\n",
    "We take $r$ to be the market daily yield of a 1-year U.S. treasury bill, inferred from annual yields obtained from The Board of Governors of the Federal Reserve via [FRED](https://fred.stlouisfed.org/series/DGS1). Since our annual time horizon consists of 253 trading days, we use...\n",
    "\n",
    "$$\n",
    "1 + r = (1 + r_{fed})^{\\frac{1}{253}}.\n",
    "$$\n",
    "\n",
    "...where $r_{fed}$ gives the Federal Reserve's reported market annual yield.\n",
    "\n",
    "Suppose we have $N + 1$ observations for the given cusip-datadate with $t=0,\\ldots,N$, such that we have $N$ observations for the first differences in variables. We then define daily drift $\\mu$ to be given by...\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu &= \\frac{1}{N}\\sum_{t=1}^N \\Delta \\log V_t \\\\\n",
    "&= \\frac{1}{N}(\\log V_N - \\log V_0).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Daily volatility $\\sigma_V$ is then given by...\n",
    "\n",
    "$$\n",
    "\\sigma_V = \\left(\\frac{1}{N-1}\\sum_{t=1}^N(\\Delta \\log V_t - \\mu)^2\\right)^{\\frac{1}{2}}.\n",
    "$$\n",
    "\n",
    "In our equity-debt-value relation, we have a nonlinear equation in 2 unknowns - $V$ and $\\sigma_V$. We proceed iteratively. \n",
    "\n",
    "We start by calculating $\\mu_E$ and $\\sigma_E$ per the above (with equity $E_t$ in place of value $V_t$), and use $\\sigma_E$ as our initial value for $\\sigma_V$. We then use this to calculate new $V_t$ for the entire cusip-datadate time series. We use this to generate a new $\\mu$ and a new $\\sigma_V$. We repeat until convergence on $\\sigma_V$, with a convergence threshold of 0.0001 following Vassalou and Xing (2004).\n",
    "\n",
    "Finally, we back out the last value of $V$ in the time series (the one applicable to the Compustat datadate) and use this to calculate distance to default $DD$ and probability of default in the next year $\\pi_D$ (naturally, these statistics hold only under Gaussianity - Gaussianity of firm value movements is an assumption that the real world violates repeatedly), given by...\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "DD &= \\frac{\\log\\left(\\frac{V}{D}\\right) + \\left(\\mu - \\frac{1}{2}\\sigma_V^2 \\right)T}{\\sigma_V \\sqrt{T}}, \\\\\n",
    "~\\\\\n",
    "\\pi_D(DD) &= \\Phi(-DD).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We use probability of default as well as distance to default as many listed firms report zero debt. This gives an infinite distance to default, which cannot be used in standard linear regression, whilst $\\pi_D(\\infty)=0$ can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6f463",
   "metadata": {},
   "source": [
    "### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb842619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from scipy.optimize import *\n",
    "from scipy.stats import *\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6154b80d",
   "metadata": {},
   "source": [
    "### Define Function to Back Out $V$\n",
    "\n",
    "Since we use `scipy.optimize` to solve the nonlinear equity-debt-value relation for $V$ given our present estimate of $\\sigma_V$ (`new_sigma_v`), as well as observed $E$ (`equity`), $D$ (`debt`), $r$ (`r`) and $T$ (`t`), we define a function to argue into `fsolve`.\n",
    "\n",
    "Note that by our equity-debt-value relation, we have...\n",
    "\n",
    "$$\n",
    "\\lim_{D \\to 0^+} \\delta_1 = \\lim_{D \\to 0^+} \\delta_2 = \\infty\n",
    "$$\n",
    "\n",
    "Thus, we have...\n",
    "$$\n",
    "V|_{D = 0} = E.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0552cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_v(v):\n",
    "        \n",
    "    if debt == 0:\n",
    "                \n",
    "        # If debt = 0 then the first cdf value is 1 (as log(v/debt) goes to infinity). And the second is irrelevant.\n",
    "            \n",
    "        F = equity - v # Will solve as v = equity\n",
    "            \n",
    "    else:\n",
    "            # This is the equity-debt-value  relation\n",
    "            \n",
    "        F = equity - (v*norm.cdf((log(v) - log(debt) + (r + 0.5*(new_sigma_v**2))*t)/(new_sigma_v*(t**0.5))) + debt*exp(-1*r)*norm.cdf((log(v) - log(debt) + (r - 0.5*(new_sigma_v**2))*t)/(new_sigma_v*(t**0.5))))\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6a04e",
   "metadata": {},
   "source": [
    "### Get List of Coefficients for Initial Guess on Equity and Debt\n",
    "\n",
    "A cursory sample of the data suggest that we find a convergent value for $\\sigma_V$ where...\n",
    "$$\n",
    "V = E + \\gamma D,~~~\\gamma \\in [0,1].\n",
    "$$\n",
    "\n",
    "Hence we loop through several initial guesses of $V$ for the algorithmic procedure of `fsolve` below, which generates values of $V$ for a given $\\sigma_V^2$. We do this following the below pattern for $\\gamma$...\n",
    "$$\n",
    "\\frac{1}{2},0,1,\\underbrace{\\frac{1}{4},\\frac{3}{4}}_{n_{odd}\\cdot2^{-2}},\\underbrace{\\frac{1}{8},\\frac{3}{8},\\frac{5}{8},\\frac{7}{8}}_{n_{odd}\\cdot 2^{-3}},\\ldots,\\underbrace{\\frac{1}{1024},\\ldots,\\frac{1021}{1024}}_{n_{odd}\\cdot2^{-10}}.\n",
    "$$\n",
    "\n",
    "Here we generate this list of potential gammas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.5,0,1] # Initial list\n",
    "\n",
    "for i in range(2,10):\n",
    "    \n",
    "    reciprocal = 2**(-1*i)\n",
    "    \n",
    "    for j in range(1, (2**i), 2):\n",
    "        \n",
    "        gammas.append(j*reciprocal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0591414",
   "metadata": {},
   "source": [
    "### Calculate Distance to Default\n",
    "\n",
    "This horrendous loop is intended to be run with cloud computing - I split the entire distance to default source data into 20 tranches in *001c_data_processing.do* to this end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ee9a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# LOOP THROUGH TRANCHES #\n",
    "#########################\n",
    "\n",
    "tranches = [1,5,9,13,17] # The specific partitions of the data we want to act on\n",
    "\n",
    "for tranche_nr in tranches:\n",
    "\n",
    "    ###################################################\n",
    "    # CHECK FOR EXISTENCE OF PARTIALLY COMPLETED DATA #\n",
    "    ###################################################\n",
    "\n",
    "    if (\"001d_dd_complete_tranche\" + str(tranche_nr) + \".dta\") not in os.listdir():\n",
    "\n",
    "        # Export an empty dataframe if a \"complete\" dataframe\n",
    "\n",
    "        pd.DataFrame(columns = [\"cusip\",\"datadate\",\"dd\", \"p_d\"]).to_stata(\"001d_dd_complete_tranche\" + str(tranche_nr) + \".dta\")\n",
    "\n",
    "\n",
    "    ########################################\n",
    "    # INITIATE DATAFRAMES (REMAINING DATA) #\n",
    "    ########################################\n",
    "\n",
    "    df = pd.read_stata(\"001_c_dd_tranche\" + str(tranche_nr) + \".dta\") # All of the source data.\n",
    "\n",
    "    all_unique_cds = df[[\"cusip\",\"datadate\"]].drop_duplicates() # Unique cusip-datadate pairs from the source data\n",
    "\n",
    "    df_dd = pd.read_stata(\"001d_dd_complete_tranche\" + str(tranche_nr) + \".dta\").drop(\"index\", axis = 1) \n",
    "                                                                                 # The dataframe to export, containing cusip,\n",
    "                                                                                # datadate, distance to default, and \n",
    "                                                                               # probability of default in  next year. This is \n",
    "                                                                              # initated as the already completed portion of the\n",
    "                                                                             #  dataframe\n",
    "\n",
    "    complete_unique_cds = df_dd[[\"cusip\",\"datadate\"]].drop_duplicates() # Already completed cusip-datadate pairs\n",
    "\n",
    "    unique_cds = pd.concat([all_unique_cds, complete_unique_cds]).drop_duplicates(keep = False) # A dataframe of *incomplete*\n",
    "                                                                                               # cusip-datadate pairs\n",
    "\n",
    "    #######################\n",
    "    # FURTHER INITIATIONS #\n",
    "    #######################\n",
    "\n",
    "    t = 253 # Always holds - the assumed number of trading days in a year.\n",
    "\n",
    "    counter = len(all_unique_cds.index) - len(unique_cds.index) # Just a counter for counting\n",
    "\n",
    "    time1 = time()\n",
    "\n",
    "\n",
    "    #########################################\n",
    "    # LOOP - CALCULATE DISTANCES TO DEFAULT #\n",
    "    #########################################\n",
    "\n",
    "    for cd in unique_cds.values: # Loops through unique cusip-datadate pairs\n",
    "\n",
    "        # GET INITIAL ESTIMATE OF LOG_V #\n",
    "\n",
    "        df_cd = df[(df[\"cusip\"] == cd[0]) & (df[\"datadate\"] == cd[1])] # This dataframe contains the time series for the \n",
    "                                                                      # specific cusip-datadate\n",
    "\n",
    "        log_vs = log(df_cd[\"equity\"]).values # Initial estimates of the V_t\n",
    "\n",
    "\n",
    "        ## CALCULATE MU ##\n",
    "\n",
    "        nr_diff_obs = len(log_vs[~isnan(log_vs)]) - 1 # Null observations only appear in the last row, so this is valid.\n",
    "\n",
    "        log_V_0 = log_vs[~isnan(log_vs)][0] # First observation of log_v (not delta log_v)\n",
    "\n",
    "        log_V_N = log_vs[~isnan(log_vs)][-1] # Last observation of log_v\n",
    "\n",
    "        mu = (log_V_N - log_V_0)/nr_diff_obs # Calculate daily drift\n",
    "\n",
    "\n",
    "        ## CALCULATE INITIAL ESTIMATE OF SIGMA_V ##\n",
    "\n",
    "        # Since equity is only calculable on trading days, debt figures are released every 3 months and *then*\n",
    "        # interpolated, and dgs1 is present for every day, I calculate delta log v as 'between consecutive trading days'.\n",
    "\n",
    "        delta_log_vs = (log_vs - roll(log_vs, 1))[~isnan(log_vs - roll(log_vs, 1))]\n",
    "\n",
    "        datadate_equity = df_cd[\"equity\"][~isnan(df_cd[\"equity\"])].values[-1]\n",
    "\n",
    "        datadate_debt = df_cd[\"debt\"].values[-1]\n",
    "\n",
    "        new_sigma_v = std(delta_log_vs - mu)*(datadate_equity/(datadate_equity + datadate_debt)) # Initial estimate of sigma_v,\n",
    "                                                                                                # following Bharath and Shumway\n",
    "                                                                                               # (2008)\n",
    "\n",
    "        old_sigma_v = 2*new_sigma_v # Prevents convergence in the first iteration\n",
    "        \n",
    "\n",
    "        ## ITERATION ##\n",
    "\n",
    "        iteration_count = 1\n",
    "\n",
    "        sigma_list = []\n",
    "\n",
    "        sigma_loop_switch = 0 # Used if sigmas do not converge and estimation gets stuck in a loop\n",
    "\n",
    "        non_convergence_switch = 0 # Used if unpatterned non-convergence occurs\n",
    "\n",
    "        estimation_failure_switch = 0 # Used if estimation of v fails for any value of v in the sample\n",
    "        \n",
    "        zero_sigma_switch = 0 # Used if neither debt nor equity \n",
    "\n",
    "        while True: # Loop broken upon convergence below\n",
    "            \n",
    "            # CHECK FOR ZERO VARIANCE #\n",
    "            \n",
    "            if new_sigma_v == 0: # This will only ever execute if equity remains the same throughout the period\n",
    "                \n",
    "                if len(df_cd[\"debt\"].unique()) > 1: # If debt fluctuates but equity doesn't we can still estimate variance\n",
    "                                                    # of v, just not with the variance of equity as our initial estimate\n",
    "                    \n",
    "                    new_sigma_v = 0.005*(mean(df_cd[\"debt\"])*0.5 + df_cd[\"equity\"].unique()[0])\n",
    "                    \n",
    "                    old_sigma_v = 2*new_sigma_v\n",
    "                \n",
    "                else: # If debt doesn't fluctuate and neither does equity, then distance to default is infinite\n",
    "                    \n",
    "                    zero_sigma_switch = 1\n",
    "                    \n",
    "                    break\n",
    "            \n",
    "            # CALCULATE NEW Vs #\n",
    "\n",
    "            v_set = []\n",
    "\n",
    "            for row in df_cd.values:\n",
    "\n",
    "                debt, equity, r = row[3:6]\n",
    "\n",
    "                if pd.isnull(equity):\n",
    "\n",
    "                    v_set.append(nan)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    v = None # Initiate value of v\n",
    "\n",
    "                    for coef in gammas:\n",
    "\n",
    "                        if fsolve(find_v, equity + coef*debt, full_output = True)[2] == 1: # Executes if solved\n",
    "\n",
    "                            v = fsolve(find_v, equity + coef*debt)[0]\n",
    "\n",
    "                            break\n",
    "\n",
    "                    if v == None:\n",
    "\n",
    "                        try: # Last resort for starting guess employed. Probably not sustainable.\n",
    "\n",
    "                            if fsolve(find_v, prev_v, full_output = True)[2] == 1: # Executes if solved\n",
    "\n",
    "                                print(\"Last resort employed\")\n",
    "\n",
    "                                v = fsolve(find_v, prev_v)[0]\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                print(\"Estimation failure\")\n",
    "\n",
    "                                v = None\n",
    "\n",
    "                                estimation_failure_switch = 1\n",
    "\n",
    "                        except:\n",
    "\n",
    "                            print(\"Estimation failure\")\n",
    "\n",
    "                            v = None\n",
    "\n",
    "                            estimation_failure_switch = 1\n",
    "\n",
    "                    v_set.append(v)\n",
    "\n",
    "                    prev_v = v # Used as last resort for starting guess\n",
    "\n",
    "            df_cd[\"v\"] = array(v_set)\n",
    "\n",
    "            # CHECK FOR ESTIMATION FAILURE # This happens in perhaps 0.1% of cases\n",
    "\n",
    "            if estimation_failure_switch == 1:\n",
    "\n",
    "                break\n",
    "\n",
    "            # CHECK FOR CONVERGENCE # This is essentially on our *previous* calculation of sigma_v\n",
    "\n",
    "            if abs(new_sigma_v/old_sigma_v - 1) < 0.0001:\n",
    "\n",
    "                break\n",
    "\n",
    "            # CHECK FOR SIGMA ESTIMATE LOOP #\n",
    "\n",
    "            # Since the convergence threshold is 10^-4, I use 4*2=8 significant figures when checking for loops\n",
    "\n",
    "            eightSF_new_sigma_v = round(new_sigma_v, 8 - (int(math.floor(math.log10(abs(new_sigma_v)))) + 1))\n",
    "\n",
    "            if eightSF_new_sigma_v in sigma_list:\n",
    "\n",
    "                print(\"Sigma estimate loop\")\n",
    "\n",
    "                sigma_loop_switch = 1\n",
    "\n",
    "                loop_sigmas = sigma_list[sigma_list.index(eightSF_new_sigma_v):]\n",
    "\n",
    "                new_sigma_v = mean(loop_sigmas)\n",
    "\n",
    "                break\n",
    "\n",
    "            # CHECK FOR UNPATTERNED NON-CONVERGENCE #\n",
    "\n",
    "            if iteration_count == 50:\n",
    "\n",
    "                if var(sigma_list[25:]) >= var(sigma_list[:25]):\n",
    "\n",
    "                    print(\"Sigma unpatterned Non-convergence\")\n",
    "\n",
    "                    new_sigma_v = mean(sigma_list[25:])\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(\"Sigma unpatterned divergence\")\n",
    "\n",
    "                    new_sigma_v = sigma_list[0] # With unpatterned divergence, we just take the original sigma estimate.\n",
    "\n",
    "                non_covergence_switch = 1\n",
    "\n",
    "                break\n",
    "\n",
    "            # APPEND TO SIGMA LIST #\n",
    "\n",
    "            sigma_list.append(eightSF_new_sigma_v)\n",
    "\n",
    "            # NEW ESTIMATE OF DAILY DRIFT #\n",
    "\n",
    "            log_vs = log(df_cd[\"v\"]).values\n",
    "\n",
    "            log_V_0 = log_vs[~isnan(log_vs)][0]\n",
    "\n",
    "            log_V_N = log_vs[~isnan(log_vs)][-1]\n",
    "\n",
    "            mu = (log_V_N - log_V_0)/nr_diff_obs\n",
    "\n",
    "            # NEW ESTIMATE OF SIGMA_V #\n",
    "\n",
    "            old_sigma_v = new_sigma_v # For checking convergence in next loop\n",
    "\n",
    "            delta_log_vs = (log_vs - roll(log_vs, 1))[~isnan(log_vs - roll(log_vs, 1))]\n",
    "\n",
    "            new_sigma_v = std(delta_log_vs - mu)\n",
    "\n",
    "            iteration_count = iteration_count + 1\n",
    "\n",
    "        ## CALCULATE DISTANCE TO, PROBABILITY OF DEFAULT ##\n",
    "\n",
    "        debt = df_cd[\"debt\"].values[-1] # Last value of debt\n",
    "\n",
    "        if sigma_loop_switch == 0 and non_convergence_switch == 0 and estimation_failure_switch == 0 and zero_sigma_switch == 0:\n",
    "\n",
    "            log_value = log(df_cd[\"v\"][df_cd[\"v\"].notnull()].values[-1]) # We carry forward the previous value of value if  \n",
    "                                                                        # equity is missing for the final observation.\n",
    "\n",
    "        elif estimation_failure_switch == 1 or zero_sigma_switch == 1:\n",
    "\n",
    "            None # We can't really do anything if our estimation has failed, and don't need to do anything if default has\n",
    "                # probability 0.\n",
    "\n",
    "        else:\n",
    "\n",
    "            equity = df_cd[\"equity\"][df_cd[\"equity\"].notnull()].values[-1] # Last valid value of equity\n",
    "\n",
    "            r = df_cd[\"dgs1\"].values[-1] # Last value of r\n",
    "\n",
    "            v = None # Initiate value of v\n",
    "\n",
    "            for coef in gammas:\n",
    "\n",
    "                if fsolve(find_v, equity + coef*debt, full_output = True)[2] == 1:\n",
    "\n",
    "                    v = fsolve(find_v, equity + coef*debt)[0]\n",
    "\n",
    "                    break\n",
    "\n",
    "            if v == None:\n",
    "\n",
    "                try: # Last resort for starting guess employed. Probably not sustainable.\n",
    "\n",
    "                    if fsolve(find_v, prev_v, full_output = True)[2] == 1:\n",
    "\n",
    "                        print(\"Last resort employed\")\n",
    "\n",
    "                        v = fsolve(find_v, prev_v)[0]\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        print(\"Estimation failure\")\n",
    "\n",
    "                        v = None\n",
    "\n",
    "                        estimation_failure_switch = 1\n",
    "\n",
    "                except:\n",
    "\n",
    "                    print(\"Estimation failure\")\n",
    "\n",
    "                    v = None\n",
    "\n",
    "                    estimation_failure_switch = 1\n",
    "\n",
    "            if estimation_failure_switch == 0:\n",
    "\n",
    "                log_value = log(v)\n",
    "\n",
    "        if debt == 0 or zero_sigma_switch == 1: # If the face value of debt is 0, then distance to default is infinite \n",
    "                                               # and probability of default is zero. Same with zero variance in market value\n",
    "            \n",
    "            dd = nan # Distance to default\n",
    "\n",
    "            p_d = 0 # Probability of default\n",
    "\n",
    "        elif estimation_failure_switch == 1:\n",
    "\n",
    "            dd = nan\n",
    "\n",
    "            p_d = nan\n",
    "\n",
    "        else:\n",
    "\n",
    "            log_debt = log(debt)\n",
    "\n",
    "            dd = (log_value - log_debt + (mu - 0.5*(new_sigma_v**2))*t)/(new_sigma_v*(t**0.5))\n",
    "\n",
    "            p_d = norm.cdf(-1*dd)\n",
    "\n",
    "        ## POPULATE NEW DATAFRAME ##\n",
    "\n",
    "        df_dd.loc[counter] = [cd[0], cd[1], dd, p_d] # cusip; datadate; distance_to_default; probability_of_default\n",
    "\n",
    "\n",
    "        ## UPDATE COUNTER ##\n",
    "\n",
    "        counter = counter + 1\n",
    "\n",
    "\n",
    "        ## PRINT SOME SUMMARY STATISTICS ##\n",
    "\n",
    "        if counter % 20 == 0:\n",
    "\n",
    "            time2 = time() - time1\n",
    "\n",
    "            print(tranche_nr, counter, dd, p_d, time2)\n",
    "\n",
    "            time1 = time()\n",
    "\n",
    "            if counter % 200 == 0:\n",
    "\n",
    "                df_dd.to_stata(\"001d_dd_complete_tranche\" + str(tranche_nr) + \".dta\", convert_dates = {\"datadate\":\"td\"})\n",
    "\n",
    "        else: print(tranche_nr, counter, dd, p_d)\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    # EXPORT FINAL DATAFRAME #\n",
    "    ##########################\n",
    "\n",
    "    df_dd.to_stata(\"001d_dd_complete_tranche\" + str(tranche_nr) + \".dta\", convert_dates = {\"datadate\":\"td\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
